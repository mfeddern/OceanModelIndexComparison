{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69c95c4-b5a1-4ed0-9a8d-1aee45559b1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Purpose\n",
    "\n",
    "Filter and calculate means of monthly mixed layer depth, temperature, X and Y seawater velocities from MOM6 for yellowtail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92741f6a-cf6c-4421-8021-f9f3933828c3",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19e4ed3-5ea5-4a24-a0e0-9a506367889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208031b6-5681-44c4-9999-d70111ab9891",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "Script assumes you have these files in a `OcModels/Data/MOM6` folder. To download necessary inputs, run:\n",
    "\n",
    "*Depth (2-d)*\n",
    "* *deptho* `wget -O ocean_static.deptho.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_derivative/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/static/ocean_static.deptho.nc`\n",
    "\n",
    "*Mixed layer depth (2-d)*\n",
    "* *MLD_003* `wget -O MLD_003.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/MLD_003.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc`\n",
    "\n",
    "*Temperature (3-d)*\n",
    "* *thetao* `wget -O thetao.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/thetao.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc`\n",
    "\n",
    "*X & Y sea water velocities (3-d)*\n",
    "* *uo_rotate* `wget -O uo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/uo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc`\n",
    "* *vo_rotate* `wget -O vo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/vo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc`\n",
    "\n",
    "Depth was based on a link Chia-Wei shared with me. The remaining queries were generated on the [CEFI Data Portal](https://psl.noaa.gov/cefi_portal/#data_access).\n",
    "* Region: NEP\n",
    "* Subregion: full domain\n",
    "* Experiment Type: hindcast\n",
    "* Output Frequency: monthly regrid\n",
    "* Release: r20250509\n",
    "* Data Category: ocean_monthly_z (for 3-d) or ocean_monthly (for 2-d)\n",
    "\n",
    "In the future, it'd be nice to do this on the raw data rather than the gridded data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8425c-53f9-48d9-b992-8975646912bd",
   "metadata": {},
   "source": [
    "## Life stage dictionary\n",
    "\n",
    "Based on [Data Availability](https://docs.google.com/document/d/1P8D0kH2xn4NYBc0ib3rYfSO0KAiyDNQ_kZgG4Qub7qY/edit?tab=t.0#heading=h.z5x77oqxpj4i), define filters for each lifestage for time, bottom depth, and latitude.\n",
    "\n",
    "For northern yellowtail, the bottom depth is used to determine the longitudinal extent, and the average is taken across the whole water column. For example, if the longitudinal extent is bottom depths 90-180m, the netCDF is filtered for isobaths where the depth is \\[90, 180], and the average is calculated for all the water \\[0, 180] at those depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c333dc5-2bae-46f0-8807-a3426e7a80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign months, latitudes, and depths to filter\n",
    "# all are integers, depths are in meters\n",
    "# filters are inclusive (closed interval), e.g. depth 0-180 includes depths 0 and 180 and every depth between\n",
    "\n",
    "lifestage_dict = {\n",
    "    \"cop\": { # copulation\n",
    "        \"min_month\": 8,\n",
    "        \"max_month\": 10,\n",
    "        \"min_lat\": 40,\n",
    "        \"max_lat\": 48,\n",
    "        \"min_depth\": 90,\n",
    "        \"max_depth\": 180\n",
    "    }, \n",
    "    \"part\": { # partuition\n",
    "        \"min_month\": 1,\n",
    "        \"max_month\": 4,\n",
    "        \"min_lat\": 40,\n",
    "        \"max_lat\": 48,\n",
    "        \"min_depth\": 0,\n",
    "        \"max_depth\": 180\n",
    "    },\n",
    "    \"larv\": { # larvae\n",
    "        \"min_month\": 2,\n",
    "        \"max_month\": 3,\n",
    "        \"min_lat\": 40,\n",
    "        \"max_lat\": 48,\n",
    "        \"min_depth\": 0,\n",
    "        \"max_depth\": 90\n",
    "    },\n",
    "    \"pjuv\": { # pelagic juvenile\n",
    "        \"min_month\": 4,\n",
    "        \"max_month\": 8,\n",
    "        \"min_lat\": 40,\n",
    "        \"max_lat\": 48,\n",
    "        \"min_depth\": 30,\n",
    "        \"max_depth\": 130\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67695ef2-f392-4e6c-9180-dab68a77800d",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883ebf01-91a6-433e-bd09-967a6178c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth is used to filter longitudinal extent\n",
    "ds_depth = xr.open_dataset(\"../../Data/MOM6/ocean_static.deptho.nc\")\n",
    "\n",
    "# mixed layer depth\n",
    "ds_mld = xr.open_dataset(\"../../Data/MOM6/MLD_003.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc\")\n",
    "\n",
    "# temperature\n",
    "ds_temp = xr.open_dataset(\"../../Data/MOM6/thetao.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc\")\n",
    "\n",
    "# X and Y sea water velocities\n",
    "ds_xv = xr.open_dataset(\"../../Data/MOM6/uo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc\")\n",
    "ds_yv = xr.open_dataset(\"../../Data/MOM6/vo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21338b48-3581-44d9-8b8f-3551fc349c4b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f669f9a3-b0a9-4507-ab39-d96929fd3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Print the size and dimensions of a dataset for a variable named 'var_name'\n",
    "If nan_bool is true, also count the number of non-NA records (# and %) for that variable\n",
    "\n",
    "Inputs:\n",
    "- dataset: xarray Dataset with the variable var_name\n",
    "- var_name: string with the variable name to count\n",
    "- nan_bool: boolean, to print record count and % for the variable\n",
    "\n",
    "Outputs:\n",
    "- None, will print output\n",
    "'''\n",
    "\n",
    "def print_ds_info(dataset, var_name, nan_bool = False):\n",
    "    denominator = dataset[var_name].size\n",
    "    print(f'{denominator} records with dimensions {dataset[var_name].shape}')\n",
    "    \n",
    "    if nan_bool:\n",
    "        numerator = np.isfinite(dataset[var_name].data).sum()\n",
    "        percent = numerator / denominator * 100\n",
    "        print(f'{numerator} records ({percent:.{2}f}%) are not np.nan')\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244752d-bfc1-4d86-856c-ef500d622c6b",
   "metadata": {},
   "source": [
    "In the future, it'd be nice to adjust these functions to have an argument to only run if the output file isn't in the directory already, so the notebook could run top to bototm and only re-caculate missing indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d73089e-6631-4955-be7d-d3ca5e96f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate annual mean for a 2-D variable\n",
    "\n",
    "Inputs:\n",
    "- var_dataset: xarray Dataset with the variable to average\n",
    "- depth_dataset: xarray Dataset with depth to filter\n",
    "- ds_var_name: string with the variable name, used to extract from var_dataset\n",
    "- df_var_name: string with the variable name, used to rename column in returned dataframe\n",
    "- filter_dict: dictionary with relevant filters\n",
    "    - min_mon, max_mon: minimum and maximum month (integers, inclusive)\n",
    "    - min_lat, max_lat: minimum and maximum latitude (integers or floats, inclusive)\n",
    "    - min_depth, max_depth: minimum and maximum depth to filter the longitudinal extent\n",
    "- print_counts: boolean, to print record count and % at each step; defaults to True for 2-D\n",
    "- monthly_mean: boolean, to calculate mean monthly and annually or just annually\n",
    "\n",
    "Outputs:\n",
    "- ds_df: pandas dataframe with an annual average of the variable\n",
    "'''\n",
    "\n",
    "def annual_mean_2d(var_dataset, depth_dataset, ds_var_name, df_var_name, filter_dict, print_counts = True, monthly_mean = False):\n",
    "\n",
    "    # start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"---\" + df_var_name + \"---\")\n",
    "    print_ds_info(var_dataset, ds_var_name, print_counts)\n",
    "    \n",
    "    # merge files\n",
    "    ds_merged = xr.merge([var_dataset, depth_dataset])\n",
    "    print_ds_info(ds_merged, ds_var_name, print_counts)\n",
    "\n",
    "    # create list with months\n",
    "    month_list = [x for x in range(filter_dict[\"min_month\"], filter_dict[\"max_month\"]+1)]\n",
    "    # select times and latitudes\n",
    "    ds_selected = ds_merged.sel(time =  ds_merged.time.dt.month.isin(month_list),\n",
    "                                lat = slice(filter_dict[\"min_lat\"], filter_dict[\"max_lat\"]))\n",
    "    print_ds_info(ds_selected, ds_var_name, print_counts)\n",
    "    \n",
    "    # mask depths\n",
    "    ds_masked = ds_selected.where(\n",
    "        (ds_selected.deptho >= filter_dict[\"min_depth\"]) & \n",
    "        (ds_selected.deptho <= filter_dict[\"max_depth\"])\n",
    "    )\n",
    "    print_ds_info(ds_masked, ds_var_name, print_counts)\n",
    "    \n",
    "    # calculate mean\n",
    "    if monthly_mean:\n",
    "        ds_mean = ds_masked[ds_var_name].groupby(['time.year', 'time.month']).mean(dim = ['time', 'lon', 'lat'])\n",
    "    else:\n",
    "        ds_mean = ds_masked[ds_var_name].groupby('time.year').mean(dim = ['time', 'lon', 'lat'])\n",
    "    \n",
    "    # create pandas dataframe\n",
    "    ds_df = ds_mean.to_dataframe()\n",
    "    \n",
    "    # rename column from dataset to dataframe variable name\n",
    "    ds_df.rename(columns = {ds_var_name:df_var_name}, inplace = True)\n",
    "\n",
    "    # end timer and print runtime\n",
    "    end_time = time.time()\n",
    "    print(f'Runtime: {round((end_time - start_time) / 60, 2)} minutes')\n",
    "\n",
    "    # write output\n",
    "    if monthly_mean:\n",
    "        ds_df.to_csv(\"../../Data/MOM6/yellowtail_MOM6_\" + df_var_name + \"_monthly.csv\")\n",
    "    else:\n",
    "        ds_df.to_csv(\"../../Data/MOM6/yellowtail_MOM6_\" + df_var_name + \".csv\")\n",
    "    \n",
    "    return ds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2fcc94-fe9f-4bcd-adcd-494b8ec101cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate annual mean for a 3-D variable\n",
    "\n",
    "Inputs:\n",
    "- var_dataset: xarray Dataset with the variable to average\n",
    "- depth_dataset: xarray Dataset with depth to filter\n",
    "- ds_var_name: string with the variable name, used to extract from var_dataset\n",
    "- df_var_name: string with the variable name, used to rename column in returned dataframe\n",
    "- filter_dict: dictionary with relevant filters\n",
    "    - min_mon, max_mon: minimum and maximum month (integers, inclusive)\n",
    "    - min_lat, max_lat: minimum and maximum latitude (integers or floats, inclusive)\n",
    "    - min_depth, max_depth: minimum and maximum depth to filter the longitudinal extent\n",
    "- print_counts: boolean, to print record count and % at each step; defaults to False for 3-D\n",
    "- monthly_mean: boolean, to calculate mean monthly and annually or just annually\n",
    "\n",
    "Outputs:\n",
    "- ds_df: pandas dataframe with an annual average of the variable\n",
    "'''\n",
    "\n",
    "def annual_mean_3d(var_dataset, depth_dataset, ds_var_name, df_var_name, filter_dict, print_counts = False, monthly_mean = False):\n",
    "\n",
    "    # start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"---\" + df_var_name + \"---\")\n",
    "    print_ds_info(var_dataset, ds_var_name, print_counts)\n",
    "    \n",
    "    # merge files\n",
    "    ds_merged = xr.merge([var_dataset, depth_dataset])\n",
    "    print_ds_info(ds_merged, ds_var_name, print_counts)\n",
    "\n",
    "    # create list with months\n",
    "    month_list = [x for x in range(filter_dict[\"min_month\"], filter_dict[\"max_month\"]+1)]\n",
    "    # select times and latitudes\n",
    "    ds_selected = ds_merged.sel(time =  ds_merged.time.dt.month.isin(month_list),\n",
    "                                lat = slice(filter_dict[\"min_lat\"], filter_dict[\"max_lat\"]))\n",
    "    print_ds_info(ds_selected, ds_var_name, print_counts)\n",
    "    \n",
    "    # mask depths\n",
    "    ds_masked = ds_selected.where(\n",
    "        (ds_selected.deptho >= filter_dict[\"min_depth\"]) & \n",
    "        (ds_selected.deptho <= filter_dict[\"max_depth\"])\n",
    "    )\n",
    "    print_ds_info(ds_masked, ds_var_name, print_counts)\n",
    "    \n",
    "    # calculate mean\n",
    "    if monthly_mean:\n",
    "        ds_mean = ds_masked[ds_var_name].groupby(['time.year', 'time.month']).mean(dim = ['time', 'z_l', 'lon', 'lat'])\n",
    "    else:\n",
    "        ds_mean = ds_masked[ds_var_name].groupby('time.year').mean(dim = ['time', 'z_l', 'lon', 'lat'])\n",
    "    \n",
    "    # create pandas dataframe\n",
    "    ds_df = ds_mean.to_dataframe()\n",
    "    \n",
    "    # rename column from dataset to dataframe variable name\n",
    "    ds_df.rename(columns = {ds_var_name:df_var_name}, inplace = True)\n",
    "\n",
    "    # end timer and print runtime\n",
    "    end_time = time.time()\n",
    "    print(f'Runtime: {round((end_time - start_time) / 60, 2)} minutes')\n",
    "\n",
    "    # write output\n",
    "    if monthly_mean:\n",
    "        ds_df.to_csv(\"../../Data/MOM6/yellowtail_MOM6_\" + df_var_name + \"_monthly.csv\")\n",
    "    else:\n",
    "        ds_df.to_csv(\"../../Data/MOM6/yellowtail_MOM6_\" + df_var_name + \".csv\")\n",
    "    \n",
    "    return ds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca0e06-ac11-4c58-826e-b98ce045543b",
   "metadata": {},
   "source": [
    "## Calculate means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ddbd77-fbde-4b5a-9877-8251b3b5bda0",
   "metadata": {},
   "source": [
    "If you would like monhtly and yearly means rather than yearly means (e.g. January 2022, February 2022 rather than 2022), then set the `monthly_mean` boolean to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cd7866-9f35-45ef-b7e2-a3d401939bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide whether means are monthly and yearly, or yearly\n",
    "monthly_mean = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28c6397-ec56-41d4-a296-23435a5d8f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---MLDpart---\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "4102912 records with dimensions (128, 94, 341)\n",
      "1804288 records (43.98%) are not np.nan\n",
      "4102912 records with dimensions (128, 94, 341)\n",
      "12416 records (0.30%) are not np.nan\n",
      "Runtime: 0.02 minutes\n",
      "---MLDlarv---\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "2051456 records with dimensions (64, 94, 341)\n",
      "902144 records (43.98%) are not np.nan\n",
      "2051456 records with dimensions (64, 94, 341)\n",
      "2944 records (0.14%) are not np.nan\n",
      "Runtime: 0.0 minutes\n",
      "---MLDpjuv---\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "5128640 records with dimensions (160, 94, 341)\n",
      "2255360 records (43.98%) are not np.nan\n",
      "5128640 records with dimensions (160, 94, 341)\n",
      "11840 records (0.23%) are not np.nan\n",
      "Runtime: 0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "# mixed layer depths\n",
    "MLDpart = annual_mean_2d(ds_mld, ds_depth, \"MLD_003\", \"MLDpart\", lifestage_dict['part'], True, monthly_mean)\n",
    "MLDlarv = annual_mean_2d(ds_mld, ds_depth, \"MLD_003\", \"MLDlarv\", lifestage_dict['larv'], True, monthly_mean)\n",
    "MLDpjuv = annual_mean_2d(ds_mld, ds_depth, \"MLD_003\", \"MLDpjuv\", lifestage_dict['pjuv'], True, monthly_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96260664-4c4f-4f74-9373-f9db312d13da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tcop---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "160013568 records with dimensions (96, 52, 94, 341)\n",
      "160013568 records with dimensions (96, 52, 94, 341)\n",
      "Runtime: 12.36 minutes\n",
      "---Tpart---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "213351424 records with dimensions (128, 52, 94, 341)\n",
      "213351424 records with dimensions (128, 52, 94, 341)\n",
      "Runtime: 16.7 minutes\n"
     ]
    }
   ],
   "source": [
    "# temperatures\n",
    "Tcop = annual_mean_3d(ds_temp, ds_depth, \"thetao\", \"Tcop\", lifestage_dict['cop'], False, monthly_mean)\n",
    "Tpart = annual_mean_3d(ds_temp, ds_depth, \"thetao\", \"Tpart\", lifestage_dict['part'], False, monthly_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e77825c4-d814-49e8-9a0b-155339dd0f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---XVlarv---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "106675712 records with dimensions (64, 52, 94, 341)\n",
      "106675712 records with dimensions (64, 52, 94, 341)\n",
      "Runtime: 8.94 minutes\n",
      "---XVpjuv---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "266689280 records with dimensions (160, 52, 94, 341)\n",
      "266689280 records with dimensions (160, 52, 94, 341)\n",
      "Runtime: 22.36 minutes\n"
     ]
    }
   ],
   "source": [
    "# X sea water velocities\n",
    "XVlarv = annual_mean_3d(ds_xv, ds_depth, \"uo_rotate\", \"XVlarv\", lifestage_dict['larv'], False, monthly_mean)\n",
    "XVpjuv = annual_mean_3d(ds_xv, ds_depth, \"uo_rotate\", \"XVpjuv\", lifestage_dict['pjuv'], False, monthly_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7659d6de-2d57-4e6c-b489-49a37fcc6898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---YVlarv---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "106675712 records with dimensions (64, 52, 94, 341)\n",
      "106675712 records with dimensions (64, 52, 94, 341)\n",
      "Runtime: 9.02 minutes\n",
      "---YVpjuv---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "266689280 records with dimensions (160, 52, 94, 341)\n",
      "266689280 records with dimensions (160, 52, 94, 341)\n",
      "Runtime: 22.2 minutes\n"
     ]
    }
   ],
   "source": [
    "# Y sea water velocities\n",
    "YVlarv = annual_mean_3d(ds_yv, ds_depth, \"vo_rotate\", \"YVlarv\", lifestage_dict['larv'], False, monthly_mean)\n",
    "YVpjuv = annual_mean_3d(ds_yv, ds_depth, \"vo_rotate\", \"YVpjuv\", lifestage_dict['pjuv'], False, monthly_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e1633-829a-4249-82f8-d957bc5f0f24",
   "metadata": {},
   "source": [
    "## Lag indices as needed\n",
    "\n",
    "For life stages where data from the prior calendar year are relevant for this year's recruitment deviaitons, adjust the index +1. For yellowtail, those life stages are preconditioning, copulation, and egg fertilization.\n",
    "\n",
    "In the future, it'd be nice to do this programatically by adding the lag to the lifestage dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740700d2-abc7-485d-8875-dd3984faf06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag copulation data by one year\n",
    "if monthly_mean:\n",
    "    # get year from multi level index and increment by 1\n",
    "    new_index = Tcop.index.get_level_values(0).unique() + 1\n",
    "    # update year index\n",
    "    Tcop.index = Tcop.index.set_levels(new_index, level = 0)\n",
    "else:\n",
    "    # increment single level year index by 1\n",
    "    Tcop.index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae4c18-a756-41ff-900d-45d8d4d23933",
   "metadata": {},
   "source": [
    "## Combine and write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8747d6c5-581c-47cc-a03f-b13987ea2234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MLDpart</th>\n",
       "      <th>MLDlarv</th>\n",
       "      <th>MLDpjuv</th>\n",
       "      <th>Tcop</th>\n",
       "      <th>Tpart</th>\n",
       "      <th>XVlarv</th>\n",
       "      <th>XVpjuv</th>\n",
       "      <th>YVlarv</th>\n",
       "      <th>YVpjuv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1993</th>\n",
       "      <th>1</th>\n",
       "      <td>15.543549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.631847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.654377</td>\n",
       "      <td>12.478229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.666722</td>\n",
       "      <td>-0.002409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024924</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.191119</td>\n",
       "      <td>9.330729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.742592</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031133</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.933027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.571263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.307956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.329814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2024</th>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.676910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.558772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2025</th>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.433339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.111207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.489971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              MLDpart    MLDlarv   MLDpjuv       Tcop      Tpart    XVlarv  \\\n",
       "year month                                                                   \n",
       "1993 1      15.543549        NaN       NaN        NaN   9.631847       NaN   \n",
       "     2      13.654377  12.478229       NaN        NaN   9.666722 -0.002409   \n",
       "     3      10.191119   9.330729       NaN        NaN   9.742592  0.000458   \n",
       "     4       7.933027        NaN  7.571263        NaN  10.307956       NaN   \n",
       "     5            NaN        NaN  6.329814        NaN        NaN       NaN   \n",
       "...               ...        ...       ...        ...        ...       ...   \n",
       "2024 9            NaN        NaN       NaN   9.676910        NaN       NaN   \n",
       "     10           NaN        NaN       NaN  10.558772        NaN       NaN   \n",
       "2025 8            NaN        NaN       NaN  13.433339        NaN       NaN   \n",
       "     9            NaN        NaN       NaN  14.111207        NaN       NaN   \n",
       "     10           NaN        NaN       NaN  13.489971        NaN       NaN   \n",
       "\n",
       "              XVpjuv    YVlarv    YVpjuv  \n",
       "year month                                \n",
       "1993 1           NaN       NaN       NaN  \n",
       "     2           NaN  0.024924       NaN  \n",
       "     3           NaN  0.031133       NaN  \n",
       "     4     -0.000745       NaN  0.026438  \n",
       "     5      0.000633       NaN -0.012727  \n",
       "...              ...       ...       ...  \n",
       "2024 9           NaN       NaN       NaN  \n",
       "     10          NaN       NaN       NaN  \n",
       "2025 8           NaN       NaN       NaN  \n",
       "     9           NaN       NaN       NaN  \n",
       "     10          NaN       NaN       NaN  \n",
       "\n",
       "[321 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge pandas dataframes\n",
    "output_df = pd.concat([MLDpart, MLDlarv, MLDpjuv, Tcop, Tpart, XVlarv, XVpjuv, YVlarv, YVpjuv], axis = 1)\n",
    "\n",
    "# sort indices\n",
    "output_df.sort_index(inplace = True)\n",
    "\n",
    "# save result\n",
    "if monthly_mean:\n",
    "    output_df.to_csv(\"../../Data/MOM6/yellowtail_MOM6_monthly.csv\")\n",
    "else:\n",
    "    output_df.to_csv(\"../../Data/MOM6/yellowtail_MOM6.csv\")\n",
    "\n",
    "# preview result\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e8f69f-3013-44d7-9c34-8ea5b872d419",
   "metadata": {},
   "source": [
    "Once spot checking the data, manually move the file from `Data/MOM6` to `Data/Yellowtail`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
