{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69c95c4-b5a1-4ed0-9a8d-1aee45559b1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Purpose\n",
    "\n",
    "Filter and calculate means of monthly mixed layer depth, temperature, X and Y seawater velocities from MOM6 for yellowtail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92741f6a-cf6c-4421-8021-f9f3933828c3",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19e4ed3-5ea5-4a24-a0e0-9a506367889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208031b6-5681-44c4-9999-d70111ab9891",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "Script assumes you have these files in a `OcModels/Data/MOM6` folder. To download necessary inputs, run:\n",
    "\n",
    "*Depth (2-d)*\n",
    "* *deptho* `wget -O ocean_static.deptho.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_derivative/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/static/ocean_static.deptho.nc`\n",
    "\n",
    "*Mixed layer depth (2-d)*\n",
    "* *MLD_003* `wget -O MLD_003.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/MLD_003.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc`\n",
    "\n",
    "*Temperature (3-d)*\n",
    "* *thetao* `wget -O thetao.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/thetao.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc`\n",
    "\n",
    "*X & Y sea water velocities (3-d)*\n",
    "* *uo_rotate* `wget -O uo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/uo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc`\n",
    "* *vo_rotate* `wget -O vo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc https://psl.noaa.gov/thredds/fileServer/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/monthly/regrid/r20250509/vo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc`\n",
    "\n",
    "Depth was based on a link Chia-Wei shared with me. The remaining queries were generated on the [CEFI Data Portal](https://psl.noaa.gov/cefi_portal/#data_access).\n",
    "* Region: NEP\n",
    "* Subregion: full domain\n",
    "* Experiment Type: hindcast\n",
    "* Output Frequency: monthly regrid\n",
    "* Release: r20250509\n",
    "* Data Category: ocean_monthly_z (for 3-d) or ocean_monthly (for 2-d)\n",
    "\n",
    "In the future, it'd be nice to do this on the raw data rather than the gridded data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8425c-53f9-48d9-b992-8975646912bd",
   "metadata": {},
   "source": [
    "## Life stage dictionary\n",
    "\n",
    "Based on [Data Availability](https://docs.google.com/document/d/1P8D0kH2xn4NYBc0ib3rYfSO0KAiyDNQ_kZgG4Qub7qY/edit?tab=t.0#heading=h.z5x77oqxpj4i), define filters for each lifestage for time, bottom depth, and latitude.\n",
    "\n",
    "For northern yellowtail, the bottom depth is used to determine the longitudinal extent, and the average is taken across the whole water column. For example, if the longitudinal extent is bottom depths 90-180m, the netCDF is filtered for isobaths where the depth is \\[90, 180], and the average is calculated for all the water \\[0, 180] at those depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c333dc5-2bae-46f0-8807-a3426e7a80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign months, latitudes, and depths to filter\n",
    "# all are integers, depths are in meters\n",
    "# filters are inclusive (closed interval), e.g. depth 0-180 includes depths 0 and 180 and every depth between\n",
    "\n",
    "lifestage_dict = {\n",
    "    \"cop\": { # copulation\n",
    "        \"min_month\": 8,\n",
    "        \"max_month\": 10,\n",
    "        \"min_lat\": 40,\n",
    "        \"max_lat\": 48,\n",
    "        \"min_depth\": 90,\n",
    "        \"max_depth\": 180\n",
    "    }, \n",
    "    \"part\": { # partuition\n",
    "        \"min_month\": 1,\n",
    "        \"max_month\": 4,\n",
    "        \"min_lat\": 40,\n",
    "        \"max_lat\": 48,\n",
    "        \"min_depth\": 0,\n",
    "        \"max_depth\": 180\n",
    "    },\n",
    "    \"larv\": { # larvae\n",
    "        \"min_month\": 2,\n",
    "        \"max_month\": 3,\n",
    "        \"min_lat\": 40,\n",
    "        \"max_lat\": 48,\n",
    "        \"min_depth\": 0,\n",
    "        \"max_depth\": 90\n",
    "    },\n",
    "    \"pjuv\": { # pelagic juvenile\n",
    "        \"min_month\": 4,\n",
    "        \"max_month\": 8,\n",
    "        \"min_lat\": 40,\n",
    "        \"max_lat\": 48,\n",
    "        \"min_depth\": 30,\n",
    "        \"max_depth\": 130\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67695ef2-f392-4e6c-9180-dab68a77800d",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883ebf01-91a6-433e-bd09-967a6178c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth is used to filter longitudinal extent\n",
    "ds_depth = xr.open_dataset(\"../../Data/MOM6/ocean_static.deptho.nc\")\n",
    "\n",
    "# mixed layer depth\n",
    "ds_mld = xr.open_dataset(\"../../Data/MOM6/MLD_003.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc\")\n",
    "\n",
    "# temperature\n",
    "ds_temp = xr.open_dataset(\"../../Data/MOM6/thetao.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc\")\n",
    "\n",
    "# X and Y sea water velocities\n",
    "ds_xv = xr.open_dataset(\"../../Data/MOM6/uo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc\")\n",
    "ds_yv = xr.open_dataset(\"../../Data/MOM6/vo_rotate.nep.full.hcast.monthly.regrid.r20250509.199301-202412.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21338b48-3581-44d9-8b8f-3551fc349c4b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f669f9a3-b0a9-4507-ab39-d96929fd3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Print the size and dimensions of a dataset for a variable named 'var_name'\n",
    "If nan_bool is true, also count the number of non-NA records (# and %) for that variable\n",
    "\n",
    "Inputs:\n",
    "- dataset: xarray Dataset with the variable var_name\n",
    "- var_name: string with the variable name to count\n",
    "- nan_bool: boolean, to print record count and % for the variable\n",
    "\n",
    "Outputs:\n",
    "- None, will print output\n",
    "'''\n",
    "\n",
    "def print_ds_info(dataset, var_name, nan_bool = False):\n",
    "    denominator = dataset[var_name].size\n",
    "    print(f'{denominator} records with dimensions {dataset[var_name].shape}')\n",
    "    \n",
    "    if nan_bool:\n",
    "        numerator = np.isfinite(dataset[var_name].data).sum()\n",
    "        percent = numerator / denominator * 100\n",
    "        print(f'{numerator} records ({percent:.{2}f}%) are not np.nan')\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244752d-bfc1-4d86-856c-ef500d622c6b",
   "metadata": {},
   "source": [
    "In the future, it'd be nice to adjust these functions to have an argument to only run if the output file isn't in the directory already, so the notebook could run top to bototm and only re-caculate missing indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d73089e-6631-4955-be7d-d3ca5e96f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate annual mean for a 2-D variable\n",
    "\n",
    "Inputs:\n",
    "- var_dataset: xarray Dataset with the variable to average\n",
    "- depth_dataset: xarray Dataset with depth to filter\n",
    "- ds_var_name: string with the variable name, used to extract from var_dataset\n",
    "- df_var_name: string with the variable name, used to rename column in returned dataframe\n",
    "- filter_dict: dictionary with relevant filters\n",
    "    - min_mon, max_mon: minimum and maximum month (integers, inclusive)\n",
    "    - min_lat, max_lat: minimum and maximum latitude (integers or floats, inclusive)\n",
    "    - min_depth, max_depth: minimum and maximum depth to filter the longitudinal extent\n",
    "- print_counts: boolean, to print record count and % at each step; defaults to True for 2-D\n",
    "\n",
    "Outputs:\n",
    "- ds_df: pandas dataframe with an annual average of the variable\n",
    "'''\n",
    "\n",
    "def annual_mean_2d(var_dataset, depth_dataset, ds_var_name, df_var_name, filter_dict, print_counts = True):\n",
    "\n",
    "    # start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"---\" + df_var_name + \"---\")\n",
    "    print_ds_info(var_dataset, ds_var_name, print_counts)\n",
    "    \n",
    "    # merge files\n",
    "    ds_merged = xr.merge([var_dataset, depth_dataset])\n",
    "    print_ds_info(ds_merged, ds_var_name, print_counts)\n",
    "\n",
    "    # create list with months\n",
    "    month_list = [x for x in range(filter_dict[\"min_month\"], filter_dict[\"max_month\"]+1)]\n",
    "    # select times and latitudes\n",
    "    ds_selected = ds_merged.sel(time =  ds_merged.time.dt.month.isin(month_list),\n",
    "                                lat = slice(filter_dict[\"min_lat\"], filter_dict[\"max_lat\"]))\n",
    "    print_ds_info(ds_selected, ds_var_name, print_counts)\n",
    "    \n",
    "    # mask depths\n",
    "    ds_masked = ds_selected.where(\n",
    "        (ds_selected.deptho >= filter_dict[\"min_depth\"]) & \n",
    "        (ds_selected.deptho <= filter_dict[\"max_depth\"])\n",
    "    )\n",
    "    print_ds_info(ds_masked, ds_var_name, print_counts)\n",
    "    \n",
    "    # calculate mean\n",
    "    ds_mean = ds_masked[ds_var_name].groupby('time.year').mean(dim = ['time', 'lon', 'lat'])\n",
    "    \n",
    "    # create pandas dataframe\n",
    "    ds_df = ds_mean.to_dataframe()\n",
    "    \n",
    "    # rename column from dataset to dataframe variable name\n",
    "    ds_df.rename(columns = {ds_var_name:df_var_name}, inplace = True)\n",
    "\n",
    "    # end timer and print runtime\n",
    "    end_time = time.time()\n",
    "    print(f'Runtime: {round((end_time - start_time) / 60, 2)} minutes')\n",
    "\n",
    "    # write output\n",
    "    ds_df.to_csv(\"../../Data/MOM6/yellowtail_MOM6_\" + df_var_name + \".csv\")\n",
    "    \n",
    "    return ds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2fcc94-fe9f-4bcd-adcd-494b8ec101cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate annual mean for a 3-D variable\n",
    "\n",
    "Inputs:\n",
    "- var_dataset: xarray Dataset with the variable to average\n",
    "- depth_dataset: xarray Dataset with depth to filter\n",
    "- ds_var_name: string with the variable name, used to extract from var_dataset\n",
    "- df_var_name: string with the variable name, used to rename column in returned dataframe\n",
    "- filter_dict: dictionary with relevant filters\n",
    "    - min_mon, max_mon: minimum and maximum month (integers, inclusive)\n",
    "    - min_lat, max_lat: minimum and maximum latitude (integers or floats, inclusive)\n",
    "    - min_depth, max_depth: minimum and maximum depth to filter the longitudinal extent\n",
    "- print_counts: boolean, to print record count and % at each step; defaults to False for 3-D\n",
    "\n",
    "Outputs:\n",
    "- ds_df: pandas dataframe with an annual average of the variable\n",
    "'''\n",
    "\n",
    "def annual_mean_3d(var_dataset, depth_dataset, ds_var_name, df_var_name, filter_dict, print_counts = False):\n",
    "\n",
    "    # start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"---\" + df_var_name + \"---\")\n",
    "    print_ds_info(var_dataset, ds_var_name, print_counts)\n",
    "    \n",
    "    # merge files\n",
    "    ds_merged = xr.merge([var_dataset, depth_dataset])\n",
    "    print_ds_info(ds_merged, ds_var_name, print_counts)\n",
    "\n",
    "    # create list with months\n",
    "    month_list = [x for x in range(filter_dict[\"min_month\"], filter_dict[\"max_month\"]+1)]\n",
    "    # select times and latitudes\n",
    "    ds_selected = ds_merged.sel(time =  ds_merged.time.dt.month.isin(month_list),\n",
    "                                lat = slice(filter_dict[\"min_lat\"], filter_dict[\"max_lat\"]))\n",
    "    print_ds_info(ds_selected, ds_var_name, print_counts)\n",
    "    \n",
    "    # mask depths\n",
    "    ds_masked = ds_selected.where(\n",
    "        (ds_selected.deptho >= filter_dict[\"min_depth\"]) & \n",
    "        (ds_selected.deptho <= filter_dict[\"max_depth\"])\n",
    "    )\n",
    "    print_ds_info(ds_masked, ds_var_name, print_counts)\n",
    "    \n",
    "    # calculate mean\n",
    "    ds_mean = ds_masked[ds_var_name].groupby('time.year').mean(dim = ['time', 'z_l', 'lon', 'lat'])\n",
    "    \n",
    "    # create pandas dataframe\n",
    "    ds_df = ds_mean.to_dataframe()\n",
    "    \n",
    "    # rename column from dataset to dataframe variable name\n",
    "    ds_df.rename(columns = {ds_var_name:df_var_name}, inplace = True)\n",
    "\n",
    "    # end timer and print runtime\n",
    "    end_time = time.time()\n",
    "    print(f'Runtime: {round((end_time - start_time) / 60, 2)} minutes')\n",
    "\n",
    "    # write output\n",
    "    ds_df.to_csv(\"../../Data/MOM6/yellowtail_MOM6_\" + df_var_name + \".csv\")\n",
    "    \n",
    "    return ds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca0e06-ac11-4c58-826e-b98ce045543b",
   "metadata": {},
   "source": [
    "## Calculate means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a28c6397-ec56-41d4-a296-23435a5d8f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---MLDpart---\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "4102912 records with dimensions (128, 94, 341)\n",
      "1804288 records (43.98%) are not np.nan\n",
      "4102912 records with dimensions (128, 94, 341)\n",
      "12416 records (0.30%) are not np.nan\n",
      "Runtime: 0.02 minutes\n",
      "---MLDlarv---\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "2051456 records with dimensions (64, 94, 341)\n",
      "902144 records (43.98%) are not np.nan\n",
      "2051456 records with dimensions (64, 94, 341)\n",
      "2944 records (0.14%) are not np.nan\n",
      "Runtime: 0.0 minutes\n",
      "---MLDpjuv---\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "106719360 records with dimensions (384, 815, 341)\n",
      "38069760 records (35.67%) are not np.nan\n",
      "5128640 records with dimensions (160, 94, 341)\n",
      "2255360 records (43.98%) are not np.nan\n",
      "5128640 records with dimensions (160, 94, 341)\n",
      "11840 records (0.23%) are not np.nan\n",
      "Runtime: 0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "# mixed layer depths\n",
    "MLDpart = annual_mean_2d(ds_mld, ds_depth, \"MLD_003\", \"MLDpart\", lifestage_dict['part'], True)\n",
    "MLDlarv = annual_mean_2d(ds_mld, ds_depth, \"MLD_003\", \"MLDlarv\", lifestage_dict['larv'], True)\n",
    "MLDpjuv = annual_mean_2d(ds_mld, ds_depth, \"MLD_003\", \"MLDpjuv\", lifestage_dict['pjuv'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96260664-4c4f-4f74-9373-f9db312d13da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tcop---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "160013568 records with dimensions (96, 52, 94, 341)\n",
      "160013568 records with dimensions (96, 52, 94, 341)\n",
      "Runtime: 12.92 minutes\n",
      "---Tpart---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "213351424 records with dimensions (128, 52, 94, 341)\n",
      "213351424 records with dimensions (128, 52, 94, 341)\n",
      "Runtime: 17.08 minutes\n"
     ]
    }
   ],
   "source": [
    "# temperatures\n",
    "Tcop = annual_mean_3d(ds_temp, ds_depth, \"thetao\", \"Tcop\", lifestage_dict['cop'], False)\n",
    "Tpart = annual_mean_3d(ds_temp, ds_depth, \"thetao\", \"Tpart\", lifestage_dict['part'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77825c4-d814-49e8-9a0b-155339dd0f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---XVlarv---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "106675712 records with dimensions (64, 52, 94, 341)\n",
      "106675712 records with dimensions (64, 52, 94, 341)\n",
      "Runtime: 9.02 minutes\n",
      "---XVpjuv---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "266689280 records with dimensions (160, 52, 94, 341)\n",
      "266689280 records with dimensions (160, 52, 94, 341)\n",
      "Runtime: 22.6 minutes\n"
     ]
    }
   ],
   "source": [
    "# X sea water velocities\n",
    "XVlarv = annual_mean_3d(ds_xv, ds_depth, \"uo_rotate\", \"XVlarv\", lifestage_dict['larv'], False)\n",
    "XVpjuv = annual_mean_3d(ds_xv, ds_depth, \"uo_rotate\", \"XVpjuv\", lifestage_dict['pjuv'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7659d6de-2d57-4e6c-b489-49a37fcc6898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---YVlarv---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "106675712 records with dimensions (64, 52, 94, 341)\n",
      "106675712 records with dimensions (64, 52, 94, 341)\n",
      "Runtime: 9.15 minutes\n",
      "---YVpjuv---\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "5549406720 records with dimensions (384, 52, 815, 341)\n",
      "266689280 records with dimensions (160, 52, 94, 341)\n",
      "266689280 records with dimensions (160, 52, 94, 341)\n",
      "Runtime: 22.7 minutes\n"
     ]
    }
   ],
   "source": [
    "# Y sea water velocities\n",
    "YVlarv = annual_mean_3d(ds_yv, ds_depth, \"vo_rotate\", \"YVlarv\", lifestage_dict['larv'], False)\n",
    "YVpjuv = annual_mean_3d(ds_yv, ds_depth, \"vo_rotate\", \"YVpjuv\", lifestage_dict['pjuv'], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e1633-829a-4249-82f8-d957bc5f0f24",
   "metadata": {},
   "source": [
    "## Lag indices as needed\n",
    "\n",
    "For life stages where data from the prior calendar year are relevant for this year's recruitment deviaitons, adjust the index +1. For yellowtail, those life stages are preconditioning, copulation, and egg fertilization.\n",
    "\n",
    "In the future, it'd be nice to do this programatically by adding the lag to the lifestage dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740700d2-abc7-485d-8875-dd3984faf06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag computation data by one year\n",
    "Tcop.index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae4c18-a756-41ff-900d-45d8d4d23933",
   "metadata": {},
   "source": [
    "## Combine and write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8747d6c5-581c-47cc-a03f-b13987ea2234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLDpart</th>\n",
       "      <th>MLDlarv</th>\n",
       "      <th>MLDpjuv</th>\n",
       "      <th>Tcop</th>\n",
       "      <th>Tpart</th>\n",
       "      <th>XVlarv</th>\n",
       "      <th>XVpjuv</th>\n",
       "      <th>YVlarv</th>\n",
       "      <th>YVpjuv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>11.830518</td>\n",
       "      <td>10.904479</td>\n",
       "      <td>6.428638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.837281</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>-0.000743</td>\n",
       "      <td>0.028028</td>\n",
       "      <td>-0.039921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>11.643274</td>\n",
       "      <td>11.090589</td>\n",
       "      <td>6.449591</td>\n",
       "      <td>9.238317</td>\n",
       "      <td>9.676904</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>0.024087</td>\n",
       "      <td>-0.078326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>10.150390</td>\n",
       "      <td>8.718237</td>\n",
       "      <td>6.199258</td>\n",
       "      <td>9.172405</td>\n",
       "      <td>9.853590</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.004624</td>\n",
       "      <td>0.036343</td>\n",
       "      <td>-0.073177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8.544428</td>\n",
       "      <td>7.829722</td>\n",
       "      <td>6.873740</td>\n",
       "      <td>8.946812</td>\n",
       "      <td>10.091395</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>-0.001964</td>\n",
       "      <td>0.018963</td>\n",
       "      <td>-0.061716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>8.017573</td>\n",
       "      <td>7.474869</td>\n",
       "      <td>5.906194</td>\n",
       "      <td>8.820283</td>\n",
       "      <td>9.323155</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>-0.004516</td>\n",
       "      <td>-0.015980</td>\n",
       "      <td>-0.057038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>11.557767</td>\n",
       "      <td>8.623075</td>\n",
       "      <td>6.338513</td>\n",
       "      <td>10.290700</td>\n",
       "      <td>11.195883</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>-0.005676</td>\n",
       "      <td>0.038934</td>\n",
       "      <td>-0.058639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>10.015160</td>\n",
       "      <td>8.873915</td>\n",
       "      <td>6.231465</td>\n",
       "      <td>9.537517</td>\n",
       "      <td>9.113604</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>-0.004414</td>\n",
       "      <td>0.068168</td>\n",
       "      <td>-0.081536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>9.018702</td>\n",
       "      <td>7.800598</td>\n",
       "      <td>6.196394</td>\n",
       "      <td>8.594275</td>\n",
       "      <td>9.422470</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>-0.003483</td>\n",
       "      <td>0.017836</td>\n",
       "      <td>-0.062540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>15.199876</td>\n",
       "      <td>14.303400</td>\n",
       "      <td>6.721168</td>\n",
       "      <td>8.697865</td>\n",
       "      <td>9.137657</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-0.003639</td>\n",
       "      <td>-0.001160</td>\n",
       "      <td>-0.067408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>10.175895</td>\n",
       "      <td>8.582202</td>\n",
       "      <td>6.576057</td>\n",
       "      <td>8.815708</td>\n",
       "      <td>9.218658</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>-0.006836</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>-0.081035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>9.900004</td>\n",
       "      <td>9.165301</td>\n",
       "      <td>6.199656</td>\n",
       "      <td>8.342187</td>\n",
       "      <td>10.497619</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>-0.059623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>8.877485</td>\n",
       "      <td>7.916284</td>\n",
       "      <td>6.108767</td>\n",
       "      <td>9.249504</td>\n",
       "      <td>9.732874</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>-0.065992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>11.410477</td>\n",
       "      <td>10.278699</td>\n",
       "      <td>6.537021</td>\n",
       "      <td>9.261232</td>\n",
       "      <td>9.822733</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>-0.003360</td>\n",
       "      <td>0.027802</td>\n",
       "      <td>-0.055384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>10.016699</td>\n",
       "      <td>10.174745</td>\n",
       "      <td>6.639136</td>\n",
       "      <td>9.118463</td>\n",
       "      <td>9.700779</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>-0.065737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>8.383568</td>\n",
       "      <td>7.566007</td>\n",
       "      <td>5.934452</td>\n",
       "      <td>8.736586</td>\n",
       "      <td>9.193892</td>\n",
       "      <td>-0.001190</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>-0.075919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>9.480513</td>\n",
       "      <td>8.124536</td>\n",
       "      <td>6.297779</td>\n",
       "      <td>9.119586</td>\n",
       "      <td>8.341159</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>-0.002757</td>\n",
       "      <td>-0.016744</td>\n",
       "      <td>-0.062438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>9.448678</td>\n",
       "      <td>9.177960</td>\n",
       "      <td>6.588812</td>\n",
       "      <td>8.837667</td>\n",
       "      <td>8.573014</td>\n",
       "      <td>-0.000508</td>\n",
       "      <td>-0.003625</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>-0.053308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>12.315300</td>\n",
       "      <td>10.180386</td>\n",
       "      <td>7.087825</td>\n",
       "      <td>9.206103</td>\n",
       "      <td>9.964980</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.004462</td>\n",
       "      <td>0.025844</td>\n",
       "      <td>-0.074277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>9.645205</td>\n",
       "      <td>9.048395</td>\n",
       "      <td>6.171937</td>\n",
       "      <td>8.815375</td>\n",
       "      <td>8.915831</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>-0.001573</td>\n",
       "      <td>0.040559</td>\n",
       "      <td>-0.076339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>9.622467</td>\n",
       "      <td>8.595460</td>\n",
       "      <td>5.990023</td>\n",
       "      <td>8.919318</td>\n",
       "      <td>8.519136</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>-0.002323</td>\n",
       "      <td>0.026463</td>\n",
       "      <td>-0.059313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>8.789337</td>\n",
       "      <td>8.362144</td>\n",
       "      <td>6.287403</td>\n",
       "      <td>8.529945</td>\n",
       "      <td>9.062445</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>-0.003732</td>\n",
       "      <td>-0.031888</td>\n",
       "      <td>-0.050138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>9.712216</td>\n",
       "      <td>9.106671</td>\n",
       "      <td>6.370755</td>\n",
       "      <td>9.533534</td>\n",
       "      <td>9.073760</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>-0.003458</td>\n",
       "      <td>0.047236</td>\n",
       "      <td>-0.045682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>9.966840</td>\n",
       "      <td>9.100803</td>\n",
       "      <td>6.466324</td>\n",
       "      <td>9.818097</td>\n",
       "      <td>11.054285</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.004263</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>-0.057951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>9.398067</td>\n",
       "      <td>7.512973</td>\n",
       "      <td>6.249111</td>\n",
       "      <td>9.986282</td>\n",
       "      <td>10.655773</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.006162</td>\n",
       "      <td>0.039881</td>\n",
       "      <td>-0.081988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>9.772830</td>\n",
       "      <td>7.841673</td>\n",
       "      <td>6.274770</td>\n",
       "      <td>9.587137</td>\n",
       "      <td>9.800328</td>\n",
       "      <td>-0.000825</td>\n",
       "      <td>-0.004797</td>\n",
       "      <td>0.053270</td>\n",
       "      <td>-0.057427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>10.641808</td>\n",
       "      <td>8.968727</td>\n",
       "      <td>6.286719</td>\n",
       "      <td>9.330580</td>\n",
       "      <td>9.603736</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>-0.001755</td>\n",
       "      <td>-0.003624</td>\n",
       "      <td>-0.055265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>11.101268</td>\n",
       "      <td>10.108418</td>\n",
       "      <td>6.232444</td>\n",
       "      <td>9.229483</td>\n",
       "      <td>10.030187</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-0.002470</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>-0.055610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>9.852244</td>\n",
       "      <td>7.844773</td>\n",
       "      <td>6.386738</td>\n",
       "      <td>9.587037</td>\n",
       "      <td>9.464018</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>-0.024253</td>\n",
       "      <td>-0.059398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>9.881425</td>\n",
       "      <td>8.873543</td>\n",
       "      <td>6.529687</td>\n",
       "      <td>9.830821</td>\n",
       "      <td>9.040565</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.004769</td>\n",
       "      <td>-0.023371</td>\n",
       "      <td>-0.063889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>9.837998</td>\n",
       "      <td>9.663205</td>\n",
       "      <td>6.008096</td>\n",
       "      <td>9.115975</td>\n",
       "      <td>9.160145</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.023465</td>\n",
       "      <td>-0.056220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>11.900953</td>\n",
       "      <td>11.619337</td>\n",
       "      <td>6.452252</td>\n",
       "      <td>9.138968</td>\n",
       "      <td>9.089793</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>-0.003105</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>-0.051088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>7.049551</td>\n",
       "      <td>5.993854</td>\n",
       "      <td>8.423209</td>\n",
       "      <td>9.808215</td>\n",
       "      <td>10.976408</td>\n",
       "      <td>-0.003218</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.026950</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.678174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MLDpart    MLDlarv   MLDpjuv       Tcop      Tpart    XVlarv  \\\n",
       "year                                                                   \n",
       "1993  11.830518  10.904479  6.428638        NaN   9.837281 -0.000976   \n",
       "1994  11.643274  11.090589  6.449591   9.238317   9.676904  0.001127   \n",
       "1995  10.150390   8.718237  6.199258   9.172405   9.853590 -0.000158   \n",
       "1996   8.544428   7.829722  6.873740   8.946812  10.091395  0.003210   \n",
       "1997   8.017573   7.474869  5.906194   8.820283   9.323155  0.001179   \n",
       "1998  11.557767   8.623075  6.338513  10.290700  11.195883  0.000093   \n",
       "1999  10.015160   8.873915  6.231465   9.537517   9.113604  0.001303   \n",
       "2000   9.018702   7.800598  6.196394   8.594275   9.422470 -0.000386   \n",
       "2001  15.199876  14.303400  6.721168   8.697865   9.137657 -0.000204   \n",
       "2002  10.175895   8.582202  6.576057   8.815708   9.218658  0.000856   \n",
       "2003   9.900004   9.165301  6.199656   8.342187  10.497619  0.001879   \n",
       "2004   8.877485   7.916284  6.108767   9.249504   9.732874  0.000449   \n",
       "2005  11.410477  10.278699  6.537021   9.261232   9.822733 -0.001087   \n",
       "2006  10.016699  10.174745  6.639136   9.118463   9.700779  0.001076   \n",
       "2007   8.383568   7.566007  5.934452   8.736586   9.193892 -0.001190   \n",
       "2008   9.480513   8.124536  6.297779   9.119586   8.341159  0.001874   \n",
       "2009   9.448678   9.177960  6.588812   8.837667   8.573014 -0.000508   \n",
       "2010  12.315300  10.180386  7.087825   9.206103   9.964980 -0.000444   \n",
       "2011   9.645205   9.048395  6.171937   8.815375   8.915831  0.000795   \n",
       "2012   9.622467   8.595460  5.990023   8.919318   8.519136  0.000945   \n",
       "2013   8.789337   8.362144  6.287403   8.529945   9.062445  0.001637   \n",
       "2014   9.712216   9.106671  6.370755   9.533534   9.073760  0.001400   \n",
       "2015   9.966840   9.100803  6.466324   9.818097  11.054285 -0.000103   \n",
       "2016   9.398067   7.512973  6.249111   9.986282  10.655773  0.000677   \n",
       "2017   9.772830   7.841673  6.274770   9.587137   9.800328 -0.000825   \n",
       "2018  10.641808   8.968727  6.286719   9.330580   9.603736  0.001110   \n",
       "2019  11.101268  10.108418  6.232444   9.229483  10.030187  0.000430   \n",
       "2020   9.852244   7.844773  6.386738   9.587037   9.464018  0.002265   \n",
       "2021   9.881425   8.873543  6.529687   9.830821   9.040565  0.000816   \n",
       "2022   9.837998   9.663205  6.008096   9.115975   9.160145  0.001052   \n",
       "2023  11.900953  11.619337  6.452252   9.138968   9.089793  0.001145   \n",
       "2024   7.049551   5.993854  8.423209   9.808215  10.976408 -0.003218   \n",
       "2025        NaN        NaN       NaN  13.678174        NaN       NaN   \n",
       "\n",
       "        XVpjuv    YVlarv    YVpjuv  \n",
       "year                                \n",
       "1993 -0.000743  0.028028 -0.039921  \n",
       "1994 -0.000629  0.024087 -0.078326  \n",
       "1995 -0.004624  0.036343 -0.073177  \n",
       "1996 -0.001964  0.018963 -0.061716  \n",
       "1997 -0.004516 -0.015980 -0.057038  \n",
       "1998 -0.005676  0.038934 -0.058639  \n",
       "1999 -0.004414  0.068168 -0.081536  \n",
       "2000 -0.003483  0.017836 -0.062540  \n",
       "2001 -0.003639 -0.001160 -0.067408  \n",
       "2002 -0.006836 -0.003152 -0.081035  \n",
       "2003 -0.002207  0.010889 -0.059623  \n",
       "2004 -0.003882  0.006706 -0.065992  \n",
       "2005 -0.003360  0.027802 -0.055384  \n",
       "2006 -0.004019  0.013631 -0.065737  \n",
       "2007 -0.003789  0.010700 -0.075919  \n",
       "2008 -0.002757 -0.016744 -0.062438  \n",
       "2009 -0.003625  0.020573 -0.053308  \n",
       "2010 -0.004462  0.025844 -0.074277  \n",
       "2011 -0.001573  0.040559 -0.076339  \n",
       "2012 -0.002323  0.026463 -0.059313  \n",
       "2013 -0.003732 -0.031888 -0.050138  \n",
       "2014 -0.003458  0.047236 -0.045682  \n",
       "2015 -0.004263  0.001472 -0.057951  \n",
       "2016 -0.006162  0.039881 -0.081988  \n",
       "2017 -0.004797  0.053270 -0.057427  \n",
       "2018 -0.001755 -0.003624 -0.055265  \n",
       "2019 -0.002470  0.008186 -0.055610  \n",
       "2020 -0.001998 -0.024253 -0.059398  \n",
       "2021 -0.004769 -0.023371 -0.063889  \n",
       "2022 -0.001103 -0.023465 -0.056220  \n",
       "2023 -0.003105  0.004670 -0.051088  \n",
       "2024  0.000348  0.026950  0.005197  \n",
       "2025       NaN       NaN       NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge pandas dataframes\n",
    "output_df = pd.concat([MLDpart, MLDlarv, MLDpjuv, Tcop, Tpart, XVlarv, XVpjuv, YVlarv, YVpjuv], axis = 1)\n",
    "\n",
    "# sort indices\n",
    "output_df.sort_index(inplace = True)\n",
    "\n",
    "# save result\n",
    "output_df.to_csv(\"../../Data/MOM6/yellowtail_MOM6.csv\")\n",
    "\n",
    "# preview result\n",
    "output_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
